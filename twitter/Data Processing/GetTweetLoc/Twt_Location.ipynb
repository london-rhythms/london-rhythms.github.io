{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get boroughs from tweet locations ###\n",
    "### Programmer: Dan Qin ###\n",
    "### Date: 26.05.2018    ###\n",
    "\n",
    "# This code is used to retrieve borough locations from tweet data extracted by Twt_Extract_Geodata.py\n",
    "# THEORY:\n",
    "# Borough locations will be extracted from the \"primary_geo\" column. The values in \"primary_geo\" are basically:\n",
    "# 1)the exact coordinates from where the tweet was created,\n",
    "# 2)place tags the user chose from a list of candidate Twitter Places when they tweeted,\n",
    "# 3)or locations provided in the user profile\n",
    "\n",
    "# METHOD:\n",
    "# 1) check the address in \"primary_geo\", if a borough is mentioned, store the borough name\n",
    "# 2) if an area is mentioned, store the borough it is referenced to\n",
    "# 3) if it's a specific place, return the coordinates using public geocoding API\n",
    "# 4) finally, check whether the coordinate points are within borough polygons\n",
    "# 5) points with unclear locations or located out of London boundary are excluded\n",
    "\n",
    "# p.s.Versions of libraries used in the code are printed at the end.\n",
    "\n",
    "#### Import libraries and data ####\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# data is collected from two time periods and will be merged into one later\n",
    "file_input = \"data/Thursday19April2018_18002300.csv\"\n",
    "file_input2 = \"data/Thursday26April2018_2300_0600.csv\"\n",
    "file_output = \"data/TwtBorough_Thur19042018.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>created_at</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>text_tweet</th>\n",
       "      <th>amount_tweeted</th>\n",
       "      <th>language</th>\n",
       "      <th>location</th>\n",
       "      <th>primary_geo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.324423e+09</td>\n",
       "      <td>WeatherWoking</td>\n",
       "      <td>Thu Apr 19 17:00:00 +0000 2018</td>\n",
       "      <td>1.524157e+12</td>\n",
       "      <td>Tmp 26.1°C Wind 8mph Press 1014.0mb Cloud 8584...</td>\n",
       "      <td>31.0</td>\n",
       "      <td>en</td>\n",
       "      <td>Woking, South East</td>\n",
       "      <td>51.33222222, -0.55777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.524343e+08</td>\n",
       "      <td>NewhavenTownWx</td>\n",
       "      <td>Thu Apr 19 17:00:01 +0000 2018</td>\n",
       "      <td>1.524157e+12</td>\n",
       "      <td>Wind 0.0 kts N. Barometer 1022.6 hPa, Falling ...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.8, 0.04666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.044014e+08</td>\n",
       "      <td>ThurrockWeather</td>\n",
       "      <td>Thu Apr 19 17:00:01 +0000 2018</td>\n",
       "      <td>1.524157e+12</td>\n",
       "      <td>19/1800 \\r\\nFcast:Fairly fine, occasional show...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>en</td>\n",
       "      <td>South Ockendon, Essex</td>\n",
       "      <td>51.49972222, 0.25027778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.789607e+09</td>\n",
       "      <td>ProforcaTheatre</td>\n",
       "      <td>Thu Apr 19 17:00:02 +0000 2018</td>\n",
       "      <td>1.524157e+12</td>\n",
       "      <td>Delighted to have @em_c_wroe and @MitchellReev...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>en</td>\n",
       "      <td>London</td>\n",
       "      <td>Hackney, London, United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.243197e+07</td>\n",
       "      <td>ElmsteadWeather</td>\n",
       "      <td>Thu Apr 19 17:00:03 +0000 2018</td>\n",
       "      <td>1.524157e+12</td>\n",
       "      <td>Wind 2.2 mph S\\r\\nBarometer 1037.7 mb,Falling ...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>en</td>\n",
       "      <td>Elmstead, Essex</td>\n",
       "      <td>51.87472222, 0.98694444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id      screen_name                      created_at  \\\n",
       "0  2.324423e+09    WeatherWoking  Thu Apr 19 17:00:00 +0000 2018   \n",
       "1  1.524343e+08   NewhavenTownWx  Thu Apr 19 17:00:01 +0000 2018   \n",
       "2  4.044014e+08  ThurrockWeather  Thu Apr 19 17:00:01 +0000 2018   \n",
       "3  2.789607e+09  ProforcaTheatre  Thu Apr 19 17:00:02 +0000 2018   \n",
       "4  7.243197e+07  ElmsteadWeather  Thu Apr 19 17:00:03 +0000 2018   \n",
       "\n",
       "      timestamp                                         text_tweet  \\\n",
       "0  1.524157e+12  Tmp 26.1°C Wind 8mph Press 1014.0mb Cloud 8584...   \n",
       "1  1.524157e+12  Wind 0.0 kts N. Barometer 1022.6 hPa, Falling ...   \n",
       "2  1.524157e+12  19/1800 \\r\\nFcast:Fairly fine, occasional show...   \n",
       "3  1.524157e+12  Delighted to have @em_c_wroe and @MitchellReev...   \n",
       "4  1.524157e+12  Wind 2.2 mph S\\r\\nBarometer 1037.7 mb,Falling ...   \n",
       "\n",
       "   amount_tweeted language               location  \\\n",
       "0            31.0       en     Woking, South East   \n",
       "1             6.0       en                    NaN   \n",
       "2             6.0       en  South Ockendon, Essex   \n",
       "3             1.0       en                 London   \n",
       "4            10.0       en        Elmstead, Essex   \n",
       "\n",
       "                       primary_geo  \n",
       "0         51.33222222, -0.55777778  \n",
       "1                 50.8, 0.04666667  \n",
       "2          51.49972222, 0.25027778  \n",
       "3  Hackney, London, United Kingdom  \n",
       "4          51.87472222, 0.98694444  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load twitter data\n",
    "# data_raw1 = pd.read_csv(file_input,index_col = 0)\n",
    "# data_raw2 = pd.read_csv(file_input2,index_col = 0)\n",
    "\n",
    "# # load twitter data (OPTIONAL)\n",
    "# # NOTICE: reading Kahina's csv requires specifying encoding and sep\n",
    "data_raw1 = pd.read_csv(file_input, sep = ';',encoding = \"ISO-8859-1\")\n",
    "data_raw2 = pd.read_csv(file_input2, sep = ';',encoding = \"ISO-8859-1\")\n",
    "\n",
    "# merge data\n",
    "data_raw = pd.concat([data_raw1,data_raw2], ignore_index=True)\n",
    "data_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id           11598\n",
       "screen_name       11598\n",
       "created_at        11598\n",
       "timestamp         11598\n",
       "text_tweet        11598\n",
       "amount_tweeted    11598\n",
       "language          11598\n",
       "location          10220\n",
       "primary_geo       11598\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check total number of tweets\n",
    "data_raw.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                               11598\n",
       "unique                               1632\n",
       "top       London, England, United Kingdom\n",
       "freq                                  772\n",
       "Name: primary_geo, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get location column from the dataframe\n",
    "twtloc = data_raw.primary_geo\n",
    "twtloc.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# london borough shapes\n",
    "with open('data/london_boroughs.geojson') as f:\n",
    "    BoroughShp = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Polygon</th>\n",
       "      <th>Borough</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>POLYGON ((-0.139075 51.41929, -0.139359 51.419...</td>\n",
       "      <td>Hounslow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Polygon   Borough\n",
       "count                                                  33        33\n",
       "unique                                                 33        33\n",
       "top     POLYGON ((-0.139075 51.41929, -0.139359 51.419...  Hounslow\n",
       "freq                                                    1         1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# borough polygons\n",
    "import shapely\n",
    "from shapely.geometry import Polygon\n",
    "from shapely.geometry import Point\n",
    "\n",
    "\n",
    "columns = [\"Polygon\",\"Borough\"]\n",
    "index = range(len(BoroughShp[\"features\"]))\n",
    "\n",
    "polys = pd.DataFrame(columns = columns, index = index)\n",
    "\n",
    "for i in range(len(index)):\n",
    "    polys[\"Polygon\"].iloc[i] = Polygon(BoroughShp[\"features\"][i][\"geometry\"][\"coordinates\"][0][0])\n",
    "    polys[\"Borough\"].iloc[i] = BoroughShp[\"features\"][i][\"properties\"][\"name\"]\n",
    "    \n",
    "polys.describe()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Preparation ####\n",
    "# list of location names above region level\n",
    "region_names = [\"East\",\"South\",\"South East\",\"London\",\"England\",\"United Kingdom\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Basildon',\n",
       " 'Billericay',\n",
       " 'Braintree',\n",
       " 'Brentwood',\n",
       " 'Brightlingsea',\n",
       " 'Buckhurst Hill',\n",
       " 'Burnham on Crouch',\n",
       " 'Canvey Island',\n",
       " 'Chafford Hundred',\n",
       " 'Chelmsford',\n",
       " 'Clackwell',\n",
       " 'Clacton on Sea',\n",
       " 'Coggeshall',\n",
       " 'Colchester',\n",
       " 'Corringham',\n",
       " 'Dovercourt',\n",
       " 'Eastwood',\n",
       " 'Epping',\n",
       " 'Frinton on Sea',\n",
       " 'Grays',\n",
       " 'Great Dunmow',\n",
       " 'Hadleigh',\n",
       " 'Halstead',\n",
       " 'Harlow',\n",
       " 'Harwich',\n",
       " 'Heybridge',\n",
       " 'Hockley',\n",
       " 'Holland on Sea',\n",
       " 'Ingatestone',\n",
       " 'Laindon',\n",
       " 'Langdon Hills',\n",
       " 'Leigh on Sea',\n",
       " 'Loughton',\n",
       " 'Maldon',\n",
       " 'Manningtree',\n",
       " 'North Shoebury',\n",
       " 'Ongar',\n",
       " 'Parkeston',\n",
       " 'Pitsea',\n",
       " 'Prettlewell',\n",
       " 'Rayleigh',\n",
       " 'Rochford',\n",
       " 'Romford',\n",
       " 'Saffron Walden',\n",
       " 'Shoeburyness',\n",
       " 'South Benfleet',\n",
       " 'South Woodham Ferrers',\n",
       " 'Southchurch',\n",
       " 'Southend on Sea',\n",
       " 'Southminster',\n",
       " 'Stanfield le Hope',\n",
       " 'Thaxted',\n",
       " 'Thorpe Bay',\n",
       " 'Tilbury',\n",
       " 'Waltham Abbey',\n",
       " 'Walton on the Naze',\n",
       " 'West Mersea',\n",
       " 'West Thurrock',\n",
       " 'West Tilbury',\n",
       " 'Westcliff on Sea',\n",
       " 'Wickford',\n",
       " 'Witham',\n",
       " 'Wivenhoe',\n",
       " 'Ashford',\n",
       " 'Broadstairs',\n",
       " 'Canterbury',\n",
       " 'Chatham',\n",
       " 'Cranbrook',\n",
       " 'Crayford',\n",
       " 'Dartford',\n",
       " 'Deal',\n",
       " 'Dover',\n",
       " 'Edenbridge',\n",
       " 'Faversham',\n",
       " 'Folkestone',\n",
       " 'Fordwich',\n",
       " 'Gillingham',\n",
       " 'Gravesend',\n",
       " 'Greenhill',\n",
       " 'Herne Bay',\n",
       " 'Hythe',\n",
       " 'Lydd',\n",
       " 'Maidstone',\n",
       " 'Margate',\n",
       " 'Minster',\n",
       " 'New Romney',\n",
       " 'Northfleet',\n",
       " 'Orpington',\n",
       " 'Paddock Wood',\n",
       " 'Queenborough',\n",
       " 'Rainham',\n",
       " 'Ramsgate',\n",
       " 'Rochester',\n",
       " 'Royal Tunbridge Wells',\n",
       " 'Sandwich',\n",
       " 'Sevenoaks',\n",
       " 'Sheerness',\n",
       " 'Sittingbourne',\n",
       " 'Snodland',\n",
       " 'Southborough',\n",
       " 'Strood',\n",
       " 'Swanley',\n",
       " 'Swanscombe and Greenhithe',\n",
       " 'Tenterden',\n",
       " 'Tonbridge',\n",
       " 'Tunbridge Wells',\n",
       " 'West Malling',\n",
       " 'Westerham',\n",
       " 'Westgate on Sea',\n",
       " 'Whitstable',\n",
       " 'Ashford',\n",
       " 'Beltchingley',\n",
       " 'Camberley',\n",
       " 'Chertsey',\n",
       " 'Croydon',\n",
       " 'Dorking',\n",
       " 'Egham',\n",
       " 'Epsom',\n",
       " 'Esher',\n",
       " 'Farnham',\n",
       " 'Godalming',\n",
       " 'Gomshall',\n",
       " 'Gratton',\n",
       " 'Great Brookham',\n",
       " 'Guildford',\n",
       " 'Haslemere',\n",
       " 'Horley',\n",
       " 'Kingston upon Thames',\n",
       " 'Leatherhead',\n",
       " 'Redhill',\n",
       " 'Reigate',\n",
       " 'Southwark',\n",
       " 'Staines upon Thames',\n",
       " 'Walton on Thames',\n",
       " 'Weybridge',\n",
       " 'Woking']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list of towns surrounding London\n",
    "# only look for towns in counties sharing border with London: Herts, Essex, Kent,Surrey, Berkshier, Bucks\n",
    "town_names = []\n",
    "neighbour_counties = [\"Herts\", \"Essex\", \"Kent\",\"Surrey\", \"Berkshier\", \"Bucks\"]\n",
    "\n",
    "town_temp = pd.read_csv(\"data/UK_towns.csv\")\n",
    "\n",
    "\n",
    "for i in range(len(town_temp.index)):\n",
    "    if town_temp.County[i] in neighbour_counties:\n",
    "        town_names.append(town_temp.Town[i])\n",
    "\n",
    "town_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### This part is abandoned for failing to find the proper geojson to work with ####\n",
    "# list of towns surrounding London and within the bounding box when retrieving twitter data\n",
    "# bounding box: [-0.5103751,51.2867602, 0.3340155, 51.6918741]\n",
    "\n",
    "# uk town shapes\n",
    "# with open('data/UK_town_wpc.json') as f:\n",
    "#     town_shp = json.load(f)\n",
    "\n",
    "# town_names2 = []\n",
    "# for i in range(len(town_poly)):\n",
    "#     if town_poly[i].intersects(bd_box):\n",
    "#         town_names2.append(town_shp[\"features\"][i][\"properties\"][\"PCON13NM\"])\n",
    "        \n",
    "# town_names2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area</th>\n",
       "      <th>Borough</th>\n",
       "      <th>PostTown</th>\n",
       "      <th>Postcode</th>\n",
       "      <th>Dialcode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Barking</td>\n",
       "      <td>Barking and Dagenham</td>\n",
       "      <td>BARKING</td>\n",
       "      <td>IG11</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Becontree</td>\n",
       "      <td>Barking and Dagenham</td>\n",
       "      <td>DAGENHAM</td>\n",
       "      <td>RM9</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Becontree Heath</td>\n",
       "      <td>Barking and Dagenham</td>\n",
       "      <td>DAGENHAM</td>\n",
       "      <td>RM8</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Castle Green</td>\n",
       "      <td>Barking and Dagenham</td>\n",
       "      <td>DAGENHAM</td>\n",
       "      <td>RM9</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Creekmouth</td>\n",
       "      <td>Barking and Dagenham</td>\n",
       "      <td>BARKING</td>\n",
       "      <td>IG11</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Area               Borough  PostTown Postcode Dialcode\n",
       "0          Barking  Barking and Dagenham   BARKING     IG11       20\n",
       "1        Becontree  Barking and Dagenham  DAGENHAM      RM9       20\n",
       "2  Becontree Heath  Barking and Dagenham  DAGENHAM      RM8       20\n",
       "3     Castle Green  Barking and Dagenham  DAGENHAM      RM9       20\n",
       "4       Creekmouth  Barking and Dagenham   BARKING     IG11       20"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list of areas in London\n",
    "area_names = pd.read_csv(\"data/London_areas.csv\")\n",
    "area_names.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Barking and Dagenham', 'Barnet', 'Bexley', 'Brent', 'Bromley', 'Camden', 'City of London', 'Croydon', 'Ealing', 'Enfield', 'Greenwich', 'Hackney', 'Hammersmith and Fulham', 'Haringey', 'Harrow', 'Havering', 'Hillingdon', 'Hounslow', 'Islington', 'Kensington and Chelsea', 'Kingston upon Thames', 'Lambeth', 'Lewisham', 'Merton', 'Newham', 'Redbridge', 'Richmond upon Thames', 'Southwark', 'Sutton', 'Tower Hamlets', 'Waltham Forest', 'Wandsworth', 'Westminster']\n"
     ]
    }
   ],
   "source": [
    "# list of boroughs\n",
    "borough_names = []\n",
    "for b in BoroughShp[\"features\"]:\n",
    "    borough_names.append(b[\"properties\"][\"name\"])\n",
    "    \n",
    "print(borough_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Get borough data from twitter locations ####\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.geocoders import GoogleV3\n",
    "\n",
    "borough = [0]* len(twtloc) # list to store borough tags\n",
    "geo_count = [0]* len(twtloc) # attribute of geo locations\n",
    "\n",
    "# loop through location data\n",
    "for i in range(len(twtloc)):\n",
    "    # if coordinates, keep it\n",
    "    try :\n",
    "        temp_loc = twtloc[i].split(\",\")\n",
    "        temp_coord = (float(temp_loc[0]),float(temp_loc[1]))\n",
    "        borough[i] = temp_coord\n",
    "        geo_count[i] = \"coord\"\n",
    "      \n",
    "    # if NaN value in twtloc\n",
    "    except AttributeError:\n",
    "        borough[i] = None\n",
    "        geo_count[i] = \"vagueLoc\"\n",
    "        \n",
    "    # if a string text\n",
    "    except ValueError:\n",
    "        # look at words before the first comma, if a borough, keep it(geo_count:\"borough\")\n",
    "        if temp_loc[0] in borough_names:\n",
    "            borough[i] = temp_loc[0]\n",
    "            geo_count[i] = \"borough\"\n",
    "            \n",
    "        # if an area, refer to the borough it belongs(geo_count:\"borough\")\n",
    "        elif temp_loc[0] in area_names[\"Area\"].values:\n",
    "            ref_temp =  area_names.loc[area_names[\"Area\"] == temp_loc[0]]\n",
    "            borough[i] = ref_temp[\"Borough\"].item()\n",
    "            geo_count[i] = \"borough\"\n",
    "            \n",
    "        # if a town outside London, convert it to null(geo_count:\"outofLdn\")\n",
    "        elif temp_loc[0] in town_names:\n",
    "            borough[i] = None\n",
    "            geo_count[i] = \"outofLdn\"\n",
    "            \n",
    "        # if direction names, convert it to null(geo_count:\"vagueLoc\")\n",
    "        elif temp_loc[0] in region_names:\n",
    "            borough[i] = None\n",
    "            geo_count[i] = \"vagueLoc\"\n",
    "            \n",
    "        # else, convert place names to coordinates(geo_count:\"place\")\n",
    "        else:\n",
    "            # comment out the \"Option\" below and check geo_count first(ensure it doesn't go over API limits)\n",
    "            \n",
    "            # Option1: use OSM Nominatim(1 request/sec)\n",
    "            # geolocator = Nominatim(format_string=\"%s, London\")\n",
    "            # location = geolocator.geocode(temp_loc[0])\n",
    "            # borough[i] = (location.latitude,location.longitude)\n",
    "           \n",
    "            # Option2: use Google Geocoding API(slow, 2500 requests/d)\n",
    "            api_k = \"AIzaSyDcuutPRGHN4-42H2iGqoQfFCWOZRbkG8Y\"            \n",
    "            geolocator = GoogleV3(api_key = api_k,timeout=5, domain=\"maps.google.co.uk\")            \n",
    "            location = geolocator.geocode(twtloc[i])            \n",
    "            borough[i] = (location.latitude,location.longitude)\n",
    "            \n",
    "            \n",
    "            geo_count[i] = \"place\"\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "borough     6621\n",
       "coord       2002\n",
       "vagueLoc    1982\n",
       "place        662\n",
       "outofLdn     331\n",
       "Name: value_count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the counts of geo values\n",
    "geo_check = pd.DataFrame({'value_count':geo_count})\n",
    "geo_check.fillna(value = np.nan, inplace = True)\n",
    "geo_check.value_count.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of locations above regional level is about 17% of total(after eliminating tweets out of London boundary). So perhaps consider dropping them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of place locations is under API limit\n",
    "# uncomment \"Option\" and run \"Get borough data\" again\n",
    "# save the borough tags to file if needed\n",
    "# borough_check.to_csv('data/borough_tag.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check whether coordinates in boroughs\n",
    "# create a copy of borough tags\n",
    "borough_cp = borough[:]\n",
    "\n",
    "for i in range(len(borough)):\n",
    "    # if coordinates, check whether it's within boroughs\n",
    "    if (type(borough[i]) == tuple):\n",
    "        pt = Point(borough[i][1],borough[i][0])\n",
    "        for p in range(len(polys.index)):\n",
    "            # if it is, store the borough name and break the loop\n",
    "            if(pt.within(polys.Polygon.iloc[p])):\n",
    "                borough_cp[i] = polys.Borough.iloc[p]\n",
    "                geo_count[i] = \"borough\"\n",
    "                break\n",
    "            # otherwise it's out of London \n",
    "            borough_cp[i] = None\n",
    "            geo_count[i] = \"outofLdn\"\n",
    "    else:\n",
    "        continue\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "borough     8526\n",
       "vagueLoc    1982\n",
       "outofLdn    1090\n",
       "Name: value_count, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the counts of geo values\n",
    "borough_check2 = pd.DataFrame({'borough':borough_cp,'value_count':geo_count})\n",
    "borough_check2.fillna(value = np.nan, inplace = True)\n",
    "borough_check2.value_count.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add borough column back to twitter data\n",
    "data_raw[\"borough\"] = borough_check2.borough.values\n",
    "\n",
    "# dump rows with null location data\n",
    "data_clean = data_raw.copy()\n",
    "data_clean = data_clean.dropna(subset = [\"borough\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>amount_tweeted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8.526000e+03</td>\n",
       "      <td>8.526000e+03</td>\n",
       "      <td>8526.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.533952e+16</td>\n",
       "      <td>1.524329e+12</td>\n",
       "      <td>2.080929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.416661e+17</td>\n",
       "      <td>2.731344e+08</td>\n",
       "      <td>3.343417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.353600e+04</td>\n",
       "      <td>1.524157e+12</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.006165e+07</td>\n",
       "      <td>1.524162e+12</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.186684e+08</td>\n",
       "      <td>1.524168e+12</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.487224e+09</td>\n",
       "      <td>1.524780e+12</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.896290e+17</td>\n",
       "      <td>1.524810e+12</td>\n",
       "      <td>103.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            user_id     timestamp  amount_tweeted\n",
       "count  8.526000e+03  8.526000e+03     8526.000000\n",
       "mean   7.533952e+16  1.524329e+12        2.080929\n",
       "std    2.416661e+17  2.731344e+08        3.343417\n",
       "min    1.353600e+04  1.524157e+12        1.000000\n",
       "25%    8.006165e+07  1.524162e+12        1.000000\n",
       "50%    3.186684e+08  1.524168e+12        1.000000\n",
       "75%    1.487224e+09  1.524780e+12        2.000000\n",
       "max    9.896290e+17  1.524810e+12      103.000000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check number of tweets left\n",
    "data_clean.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save it to file\n",
    "data_clean.to_csv(file_output,index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a result, 7847 tweets remain with location in boroughs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version:3.6.2 (v3.6.2:5fd33b5, Jul  8 2017, 04:57:36) [MSC v.1900 64 bit (AMD64)]\n",
      "Pandas version:0.22.0\n",
      "Numpy version:1.14.2\n",
      "Shapely version:1.6.4.post1\n",
      "Geopy version:1.13.0\n"
     ]
    }
   ],
   "source": [
    "# versions of libraries used \n",
    "import sys\n",
    "import geopy\n",
    "\n",
    "print(\"Python version:{}\".format(sys.version))\n",
    "print(\"Pandas version:{}\".format(pd.__version__))\n",
    "print(\"Numpy version:{}\".format(np.__version__))\n",
    "print(\"Shapely version:{}\".format(shapely.__version__))\n",
    "print(\"Geopy version:{}\".format(geopy.__version__))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
